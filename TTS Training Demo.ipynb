{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e62d296",
   "metadata": {},
   "source": [
    "# Saarthi TTS Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1517a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from trainer import Trainer, TrainerArgs\n",
    "import torch\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models.vits import CharactersConfig, Vits, VitsArgs, VitsAudioConfig\n",
    "from TTS.tts.utils.languages import LanguageManager\n",
    "from TTS.tts.utils.speakers import SpeakerManager\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.config import load_config\n",
    "from TTS.tts.models import setup_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c17ca0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './'\n",
    "\n",
    "mailabs_path = \"hindi_temp/**\"\n",
    "dataset_paths = glob(mailabs_path)\n",
    "dataset_config = [\n",
    "    BaseDatasetConfig(name=\"mailabs\", meta_file_train=None, path=path, language=path.split(\"/\")[-1])\n",
    "    for path in dataset_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c348c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonems = '|k_|K_|g_|j_|J_|X_|x_f_K_k_G_g_|y_w_h_C_c_J_i_y_Y_V_q_x_X_N_S_r_T_t_D_d_n~_n_`I_I_P_p_B_b_m_z_s_Aː_A_Iː_i_u_Uː_R_Oː_O_eː_e_Eː_oː_o_M_h_a_`a_v_j_l_`l'\n",
    "dev = ''.join([chr(i) for i in range(0x0900, 0x097F)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b470d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_config = VitsAudioConfig(\n",
    "    sample_rate=16000,\n",
    "    win_length=1024,\n",
    "    hop_length=256,\n",
    "    num_mels=80,\n",
    "    mel_fmin=0,\n",
    "    mel_fmax=None,\n",
    ")\n",
    "\n",
    "vitsArgs = VitsArgs(\n",
    "    use_speaker_embedding=True,\n",
    "    speaker_embedding_channels=512,\n",
    "    use_language_embedding=True,\n",
    "    embedded_language_dim=512,\n",
    "    use_sdp=False,\n",
    "    num_speakers=50,\n",
    "    # freeze_encoder=True,\n",
    "    # freeze_PE=True,\n",
    "    # freeze_DP=True,\n",
    "    # freeze_flow_decoder=True,\n",
    "    # freeze_waveform_decoder=True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ead41ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = VitsConfig(\n",
    "    model_args=vitsArgs,\n",
    "    audio=audio_config,\n",
    "    speaker_embedding_channels=512,\n",
    "    run_name=\"hindi_female\",\n",
    "    batch_size=48,\n",
    "    eval_batch_size=16,\n",
    "    batch_group_size=0,\n",
    "    num_loader_workers=4,\n",
    "    num_eval_loader_workers=4,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=1000,\n",
    "    save_step=100,\n",
    "    save_n_checkpoints=10,\n",
    "    text_cleaner=None,\n",
    "    use_phonemes=False,\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    compute_input_seq_cache=False,\n",
    "    use_language_weighted_sampler=False,\n",
    "    print_eval=False,\n",
    "    mixed_precision=False,\n",
    "    # sort_by_audio_len=True,\n",
    "    min_audio_len=16 * 128 * 4,\n",
    "    max_audio_len=160000,\n",
    "    output_path=output_path,\n",
    "    datasets=dataset_config,\n",
    "    characters=CharactersConfig(\n",
    "        pad=\"<PAD>\",\n",
    "        eos=\"<EOS>\",\n",
    "        bos=\"<BOS>\",\n",
    "        blank=\"<BLNK>\",\n",
    "        characters= dev,\n",
    "        punctuations= \",?.!;:'‘¡\",\n",
    "        phonemes= dev,\n",
    "        \n",
    "    ),\n",
    "    test_sentences=[\n",
    "        [\n",
    "            \"हाय क्या मैं ओंकार से बात कर रहा हूँ ?\",\n",
    "            \"hindi_female\",\n",
    "            None,\n",
    "            \"hindi\",\n",
    "        ],\n",
    "    ],\n",
    "    num_speakers=50,\n",
    "    use_speaker_embedding = True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b648beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 1501 files in /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/hindi_temp/hindi\n"
     ]
    }
   ],
   "source": [
    "config.from_dict(config.to_dict())\n",
    "\n",
    "# init audio processor\n",
    "ap = AudioProcessor(**config.audio.to_dict())\n",
    "\n",
    "# load training samples\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size,\n",
    ")\n",
    "\n",
    "# print(eval_samples)\n",
    "speaker_manager = SpeakerManager()\n",
    "# speaker_manager.load_ids_from_file('model_config/speakers.pth')\n",
    "# speaker_manager = SpeakerManager(speaker_id_file_path='model_config/speakers.pth')\n",
    "speaker_manager.set_ids_from_data(train_samples + eval_samples, parse_key=\"speaker_name\")\n",
    "config.model_args.num_speakers = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec5f935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab is  ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "final Vocab:  ['<PAD>', '<EOS>', '<BOS>', '<BLNK>', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '!', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', ' ']\n",
      "vocab is  ['ऀ', 'ँ', 'ं', 'ः', 'ऄ', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'ऩ', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ऱ', 'ल', 'ळ', 'ऴ', 'व', 'श', 'ष', 'स', 'ह', 'ऺ', 'ऻ', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्', 'ॎ', 'ॏ', 'ॐ', '॑', '॒', '॓', '॔', 'ॕ', 'ॖ', 'ॗ', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॠ', 'ॡ', 'ॢ', 'ॣ', '।', '॥', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '॰', 'ॱ', 'ॲ', 'ॳ', 'ॴ', 'ॵ', 'ॶ', 'ॷ', 'ॸ', 'ॹ', 'ॺ', 'ॻ', 'ॼ', 'ॽ', 'ॾ']\n",
      "final Vocab:  ['<PAD>', '<EOS>', '<BOS>', '<BLNK>', 'ऀ', 'ँ', 'ं', 'ः', 'ऄ', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'ऩ', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ऱ', 'ल', 'ळ', 'ऴ', 'व', 'श', 'ष', 'स', 'ह', 'ऺ', 'ऻ', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्', 'ॎ', 'ॏ', 'ॐ', '॑', '॒', '॓', '॔', 'ॕ', 'ॖ', 'ॗ', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॠ', 'ॡ', 'ॢ', 'ॣ', '।', '॥', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '॰', 'ॱ', 'ॲ', 'ॳ', 'ॴ', 'ॵ', 'ॶ', 'ॷ', 'ॸ', 'ॹ', 'ॺ', 'ॻ', 'ॼ', 'ॽ', 'ॾ', ',', '?', '.', '!', ';', ':', \"'\", '‘', '¡']\n"
     ]
    }
   ],
   "source": [
    "language_manager = LanguageManager(config=config)\n",
    "config.model_args.num_languages = 11\n",
    "# language_manager.load_ids_from_file('model_config/language_ids.json')\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80490701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speakers:  50\n",
      " > initialization of speaker-embedding layers.\n",
      " > initialization of language-embedding layers.\n"
     ]
    }
   ],
   "source": [
    "model = Vits(config, ap, tokenizer, speaker_manager, language_manager)\n",
    "# cp = torch.load('model_config/checkpoint_1433000.pth', \n",
    "#                 map_location=torch.device('cuda'))\n",
    "# model_weights = cp['model'].copy()\n",
    "# for key in list(model_weights.keys()):\n",
    "#   if \"speaker_encoder\" in key:\n",
    "#     del model_weights[key]\n",
    "# model.load_state_dict(model_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "594b4963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters  115227645\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Number of parameters \", count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f78402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 10:20:27,165.165 DEBUG local:  open file: /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/./hindi_female-June-15-2023_10+20AM-f6af544/config.json\n",
      "2023-06-15 10:20:27,262.262 DEBUG local:  open file: /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/./hindi_female-June-15-2023_10+20AM-f6af544/speakers.pth\n",
      "2023-06-15 10:20:27,265.265 DEBUG local:  open file: /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/./hindi_female-June-15-2023_10+20AM-f6af544/language_ids.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > `speakers.pth` is saved to ./hindi_female-June-15-2023_10+20AM-f6af544/speakers.pth.\n",
      " > `speakers_file` is updated in the config.json.\n",
      " > `language_ids.json` is saved to ./hindi_female-June-15-2023_10+20AM-f6af544/language_ids.json.\n",
      " > `language_ids_file` is updated in the config.json.\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 1486\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 144\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 77.88155339805826\n",
      " | \n",
      " | > Max audio length: 159914.0\n",
      " | > Min audio length: 24078.0\n",
      " | > Avg audio length: 104600.20194174757\n",
      " | > Num. instances discarded samples: 456\n",
      " | > Batch group size: 0.\n",
      " [!] Character ' ' not found in the vocabulary. Discarding it. [!] Character ' ' not found in the vocabulary. Discarding it. [!] Character ' ' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\n",
      " [!] Character ' ' not found in the vocabulary. Discarding it.\n",
      " [!] Character '\\xa0' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 15\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 116\n",
      " | > Min text length: 52\n",
      " | > Avg text length: 79.16666666666667\n",
      " | \n",
      " | > Max audio length: 155270.0\n",
      " | > Min audio length: 64175.0\n",
      " | > Avg audio length: 98906.16666666667\n",
      " | > Num. instances discarded samples: 3\n",
      " | > Batch group size: 0.\n",
      " [!] Character ' ' not found in the vocabulary. Discarding it.\n",
      " | > Synthesizing test sentences.\n",
      " [!] Character ' ' not found in the vocabulary. Discarding it.\n",
      "torch.Size([1, 1, 68]) torch.Size([1, 1, 68]) 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/TTS/tts/models/vits.py:1478: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/TensorShape.cpp:2981.)\n",
      "  test_figures[\"{}-alignment\".format(idx)] = plot_alignment(alignment.T, output_fig=False)\n",
      "2023-06-15 10:20:43,844.844 DEBUG local:  open file: /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/./hindi_female-June-15-2023_10+20AM-f6af544/best_model_22.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "\t| > 1 not found characters:\n",
      "\t| >  \n",
      "| > Number of instances : 1486\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 144\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 77.88155339805826\n",
      " | \n",
      " | > Max audio length: 159914.0\n",
      " | > Min audio length: 24078.0\n",
      " | > Avg audio length: 104600.20194174757\n",
      " | > Num. instances discarded samples: 456\n",
      " | > Batch group size: 0.\n",
      " [!] Character '\\xa0' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "\t| > 1 not found characters:\n",
      "\t| >  \n",
      "| > Number of instances : 15\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 116\n",
      " | > Min text length: 52\n",
      " | > Avg text length: 79.16666666666667\n",
      " | \n",
      " | > Max audio length: 155270.0\n",
      " | > Min audio length: 64175.0\n",
      " | > Avg audio length: 98906.16666666667\n",
      " | > Num. instances discarded samples: 3\n",
      " | > Batch group size: 0.\n",
      " | > Synthesizing test sentences.\n",
      "torch.Size([1, 1, 68]) torch.Size([1, 1, 68]) 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 10:21:04,856.856 DEBUG local:  open file: /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/./hindi_female-June-15-2023_10+20AM-f6af544/best_model_44.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "\t| > 1 not found characters:\n",
      "\t| >  \n",
      "| > Number of instances : 1486\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 144\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 77.88155339805826\n",
      " | \n",
      " | > Max audio length: 159914.0\n",
      " | > Min audio length: 24078.0\n",
      " | > Avg audio length: 104600.20194174757\n",
      " | > Num. instances discarded samples: 456\n",
      " | > Batch group size: 0.\n",
      " [!] Character '\\xa0' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "\t| > 1 not found characters:\n",
      "\t| >  \n",
      "| > Number of instances : 15\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 116\n",
      " | > Min text length: 52\n",
      " | > Avg text length: 79.16666666666667\n",
      " | \n",
      " | > Max audio length: 155270.0\n",
      " | > Min audio length: 64175.0\n",
      " | > Avg audio length: 98906.16666666667\n",
      " | > Num. instances discarded samples: 3\n",
      " | > Batch group size: 0.\n",
      " | > Synthesizing test sentences.\n",
      "torch.Size([1, 1, 68]) torch.Size([1, 1, 68]) 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 10:21:24,717.717 DEBUG local:  open file: /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/./hindi_female-June-15-2023_10+20AM-f6af544/best_model_66.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "\t| > 1 not found characters:\n",
      "\t| >  \n",
      "| > Number of instances : 1486\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 144\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 77.88155339805826\n",
      " | \n",
      " | > Max audio length: 159914.0\n",
      " | > Min audio length: 24078.0\n",
      " | > Avg audio length: 104600.20194174757\n",
      " | > Num. instances discarded samples: 456\n",
      " | > Batch group size: 0.\n",
      " [!] Character '\\xa0' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "\t| > 1 not found characters:\n",
      "\t| >  \n",
      "| > Number of instances : 15\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 116\n",
      " | > Min text length: 52\n",
      " | > Avg text length: 79.16666666666667\n",
      " | \n",
      " | > Max audio length: 155270.0\n",
      " | > Min audio length: 64175.0\n",
      " | > Avg audio length: 98906.16666666667\n",
      " | > Num. instances discarded samples: 3\n",
      " | > Batch group size: 0.\n",
      " | > Synthesizing test sentences.\n",
      "torch.Size([1, 1, 68]) torch.Size([1, 1, 68]) 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 10:21:44,294.294 DEBUG local:  open file: /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/./hindi_female-June-15-2023_10+20AM-f6af544/best_model_88.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "\t| > 1 not found characters:\n",
      "\t| >  \n",
      "| > Number of instances : 1486\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 144\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 77.88155339805826\n",
      " | \n",
      " | > Max audio length: 159914.0\n",
      " | > Min audio length: 24078.0\n",
      " | > Avg audio length: 104600.20194174757\n",
      " | > Num. instances discarded samples: 456\n",
      " | > Batch group size: 0.\n",
      " [!] Character '\\xa0' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 10:21:55,681.681 DEBUG local:  open file: /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/./hindi_female-June-15-2023_10+20AM-f6af544/checkpoint_100.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "\t| > 1 not found characters:\n",
      "\t| >  \n",
      "| > Number of instances : 15\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 116\n",
      " | > Min text length: 52\n",
      " | > Avg text length: 79.16666666666667\n",
      " | \n",
      " | > Max audio length: 155270.0\n",
      " | > Min audio length: 64175.0\n",
      " | > Avg audio length: 98906.16666666667\n",
      " | > Num. instances discarded samples: 3\n",
      " | > Batch group size: 0.\n",
      " | > Synthesizing test sentences.\n",
      "torch.Size([1, 1, 68]) torch.Size([1, 1, 68]) 1.0\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "\t| > 1 not found characters:\n",
      "\t| >  \n",
      "| > Number of instances : 1486\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 144\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 77.88155339805826\n",
      " | \n",
      " | > Max audio length: 159914.0\n",
      " | > Min audio length: 24078.0\n",
      " | > Avg audio length: 104600.20194174757\n",
      " | > Num. instances discarded samples: 456\n",
      " | > Batch group size: 0.\n",
      " [!] Character '\\xa0' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "\t| > 1 not found characters:\n",
      "\t| >  \n",
      "| > Number of instances : 15\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 116\n",
      " | > Min text length: 52\n",
      " | > Avg text length: 79.16666666666667\n",
      " | \n",
      " | > Max audio length: 155270.0\n",
      " | > Min audio length: 64175.0\n",
      " | > Avg audio length: 98906.16666666667\n",
      " | > Num. instances discarded samples: 3\n",
      " | > Batch group size: 0.\n",
      " | > Synthesizing test sentences.\n",
      "torch.Size([1, 1, 68]) torch.Size([1, 1, 68]) 1.0\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "\t| > 1 not found characters:\n",
      "\t| >  \n",
      "| > Number of instances : 1486\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 144\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 77.88155339805826\n",
      " | \n",
      " | > Max audio length: 159914.0\n",
      " | > Min audio length: 24078.0\n",
      " | > Avg audio length: 104600.20194174757\n",
      " | > Num. instances discarded samples: 456\n",
      " | > Batch group size: 0.\n",
      " [!] Character '\\xa0' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "\t| > 1 not found characters:\n",
      "\t| >  \n",
      "| > Number of instances : 15\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 116\n",
      " | > Min text length: 52\n",
      " | > Avg text length: 79.16666666666667\n",
      " | \n",
      " | > Max audio length: 155270.0\n",
      " | > Min audio length: 64175.0\n",
      " | > Avg audio length: 98906.16666666667\n",
      " | > Num. instances discarded samples: 3\n",
      " | > Batch group size: 0.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")\n",
    "\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47554118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
