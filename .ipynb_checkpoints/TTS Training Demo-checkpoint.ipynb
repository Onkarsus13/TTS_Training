{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e62d296",
   "metadata": {},
   "source": [
    "# Saarthi TTS Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b1517a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from trainer import Trainer, TrainerArgs\n",
    "import torch\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models.vits import CharactersConfig, Vits, VitsArgs, VitsAudioConfig\n",
    "from TTS.tts.utils.languages import LanguageManager\n",
    "from TTS.tts.utils.speakers import SpeakerManager\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.config import load_config\n",
    "from TTS.tts.models import setup_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17ca0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './TTS_Training'\n",
    "\n",
    "mailabs_path = \"hindi_temp/**\"\n",
    "dataset_paths = glob(mailabs_path)\n",
    "dataset_config = [\n",
    "    BaseDatasetConfig(name=\"mailabs\", meta_file_train=None, path=path, language=path.split(\"/\")[-1])\n",
    "    for path in dataset_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c348c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonems = '|k_|K_|g_|j_|J_|X_|x_f_K_k_G_g_|y_w_h_C_c_J_i_y_Y_V_q_x_X_N_S_r_T_t_D_d_n~_n_`I_I_P_p_B_b_m_z_s_Aː_A_Iː_i_u_Uː_R_Oː_O_eː_e_Eː_oː_o_M_h_a_`a_v_j_l_`l'\n",
    "dev = ''.join([chr(i) for i in range(0x0900, 0x097F)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b470d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_config = VitsAudioConfig(\n",
    "    sample_rate=16000,\n",
    "    win_length=1024,\n",
    "    hop_length=256,\n",
    "    num_mels=80,\n",
    "    mel_fmin=0,\n",
    "    mel_fmax=None,\n",
    ")\n",
    "\n",
    "vitsArgs = VitsArgs(\n",
    "    use_speaker_embedding=True,\n",
    "    speaker_embedding_channels=512,\n",
    "    use_language_embedding=True,\n",
    "    embedded_language_dim=512,\n",
    "    use_sdp=False,\n",
    "    num_speakers=50,\n",
    "    # freeze_encoder=True,\n",
    "    # freeze_PE=True,\n",
    "    # freeze_DP=True,\n",
    "    # freeze_flow_decoder=True,\n",
    "    # freeze_waveform_decoder=True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead41ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = VitsConfig(\n",
    "    model_args=vitsArgs,\n",
    "    audio=audio_config,\n",
    "    speaker_embedding_channels=512,\n",
    "    run_name=\"hindi_female\",\n",
    "    batch_size=48,\n",
    "    eval_batch_size=16,\n",
    "    batch_group_size=0,\n",
    "    num_loader_workers=4,\n",
    "    num_eval_loader_workers=4,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=1000,\n",
    "    save_step=100,\n",
    "    save_n_checkpoints=10,\n",
    "    text_cleaner=None,\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    compute_input_seq_cache=False,\n",
    "    use_language_weighted_sampler=False,\n",
    "    print_eval=False,\n",
    "    mixed_precision=False,\n",
    "    # sort_by_audio_len=True,\n",
    "    min_audio_len=16 * 128 * 4,\n",
    "    max_audio_len=160000,\n",
    "    output_path=output_path,\n",
    "    datasets=dataset_config,\n",
    "    characters=CharactersConfig(\n",
    "        pad=\"<PAD>\",\n",
    "        eos=\"<EOS>\",\n",
    "        bos=\"<BOS>\",\n",
    "        blank=\"<BLNK>\",\n",
    "        characters= dev,\n",
    "        punctuations= \",?.!;:'‘¡\",\n",
    "        phonemes= dev,\n",
    "        \n",
    "    ),\n",
    "    test_sentences=[\n",
    "        [\n",
    "            \"हाय क्या मैं ओंकार से बात कर रहा हूँ ?\",\n",
    "            \"saarthi_oria_male\",\n",
    "            None,\n",
    "            \"odia\",\n",
    "        ],\n",
    "    ],\n",
    "    num_speakers=50,\n",
    "    use_speaker_embedding = True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b648beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 1501 files in /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/hindi_temp/hindi\n"
     ]
    }
   ],
   "source": [
    "config.from_dict(config.to_dict())\n",
    "\n",
    "# init audio processor\n",
    "ap = AudioProcessor(**config.audio.to_dict())\n",
    "\n",
    "# load training samples\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size,\n",
    ")\n",
    "\n",
    "# print(eval_samples)\n",
    "speaker_manager = SpeakerManager()\n",
    "# speaker_manager.load_ids_from_file('model_config/speakers.pth')\n",
    "# speaker_manager = SpeakerManager(speaker_id_file_path='model_config/speakers.pth')\n",
    "speaker_manager.set_ids_from_data(train_samples + eval_samples, parse_key=\"speaker_name\")\n",
    "config.model_args.num_speakers = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5f935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab is  ['i', 'y', 'ɨ', 'ʉ', 'ɯ', 'u', 'ɪ', 'ʏ', 'ʊ', 'e', 'ø', 'ɘ', 'ə', 'ɵ', 'ɤ', 'o', 'ɛ', 'œ', 'ɜ', 'ɞ', 'ʌ', 'ɔ', 'æ', 'ɐ', 'a', 'ɶ', 'ɑ', 'ɒ', 'ᵻ', 'ʘ', 'ɓ', 'ǀ', 'ɗ', 'ǃ', 'ʄ', 'ǂ', 'ɠ', 'ǁ', 'ʛ', 'p', 'b', 't', 'd', 'ʈ', 'ɖ', 'c', 'ɟ', 'k', 'ɡ', 'q', 'ɢ', 'ʔ', 'ɴ', 'ŋ', 'ɲ', 'ɳ', 'n', 'ɱ', 'm', 'ʙ', 'r', 'ʀ', 'ⱱ', 'ɾ', 'ɽ', 'ɸ', 'β', 'f', 'v', 'θ', 'ð', 's', 'z', 'ʃ', 'ʒ', 'ʂ', 'ʐ', 'ç', 'ʝ', 'x', 'ɣ', 'χ', 'ʁ', 'ħ', 'ʕ', 'h', 'ɦ', 'ɬ', 'ɮ', 'ʋ', 'ɹ', 'ɻ', 'j', 'ɰ', 'l', 'ɭ', 'ʎ', 'ʟ', 'ˈ', 'ˌ', 'ː', 'ˑ', 'ʍ', 'w', 'ɥ', 'ʜ', 'ʢ', 'ʡ', 'ɕ', 'ʑ', 'ɺ', 'ɧ', 'ʲ', 'ɚ', '˞', 'ɫ']\n",
      "final Vocab:  ['<PAD>', '<EOS>', '<BOS>', '<BLNK>', 'a', 'b', 'c', 'd', 'e', 'f', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'æ', 'ç', 'ð', 'ø', 'ħ', 'ŋ', 'œ', 'ǀ', 'ǁ', 'ǂ', 'ǃ', 'ɐ', 'ɑ', 'ɒ', 'ɓ', 'ɔ', 'ɕ', 'ɖ', 'ɗ', 'ɘ', 'ə', 'ɚ', 'ɛ', 'ɜ', 'ɞ', 'ɟ', 'ɠ', 'ɡ', 'ɢ', 'ɣ', 'ɤ', 'ɥ', 'ɦ', 'ɧ', 'ɨ', 'ɪ', 'ɫ', 'ɬ', 'ɭ', 'ɮ', 'ɯ', 'ɰ', 'ɱ', 'ɲ', 'ɳ', 'ɴ', 'ɵ', 'ɶ', 'ɸ', 'ɹ', 'ɺ', 'ɻ', 'ɽ', 'ɾ', 'ʀ', 'ʁ', 'ʂ', 'ʃ', 'ʄ', 'ʈ', 'ʉ', 'ʊ', 'ʋ', 'ʌ', 'ʍ', 'ʎ', 'ʏ', 'ʐ', 'ʑ', 'ʒ', 'ʔ', 'ʕ', 'ʘ', 'ʙ', 'ʛ', 'ʜ', 'ʝ', 'ʟ', 'ʡ', 'ʢ', 'ʲ', 'ˈ', 'ˌ', 'ː', 'ˑ', '˞', 'β', 'θ', 'χ', 'ᵻ', 'ⱱ', '!', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', ' ']\n",
      "vocab is  ['ऀ', 'ँ', 'ं', 'ः', 'ऄ', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'ऩ', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ऱ', 'ल', 'ळ', 'ऴ', 'व', 'श', 'ष', 'स', 'ह', 'ऺ', 'ऻ', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्', 'ॎ', 'ॏ', 'ॐ', '॑', '॒', '॓', '॔', 'ॕ', 'ॖ', 'ॗ', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॠ', 'ॡ', 'ॢ', 'ॣ', '।', '॥', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '॰', 'ॱ', 'ॲ', 'ॳ', 'ॴ', 'ॵ', 'ॶ', 'ॷ', 'ॸ', 'ॹ', 'ॺ', 'ॻ', 'ॼ', 'ॽ', 'ॾ']\n",
      "final Vocab:  ['<PAD>', '<EOS>', '<BOS>', '<BLNK>', 'ऀ', 'ँ', 'ं', 'ः', 'ऄ', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'ऩ', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ऱ', 'ल', 'ळ', 'ऴ', 'व', 'श', 'ष', 'स', 'ह', 'ऺ', 'ऻ', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्', 'ॎ', 'ॏ', 'ॐ', '॑', '॒', '॓', '॔', 'ॕ', 'ॖ', 'ॗ', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॠ', 'ॡ', 'ॢ', 'ॣ', '।', '॥', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '॰', 'ॱ', 'ॲ', 'ॳ', 'ॴ', 'ॵ', 'ॶ', 'ॷ', 'ॸ', 'ॹ', 'ॺ', 'ॻ', 'ॼ', 'ॽ', 'ॾ', ',', '?', '.', '!', ';', ':', \"'\", '‘', '¡']\n"
     ]
    }
   ],
   "source": [
    "language_manager = LanguageManager(config=config)\n",
    "config.model_args.num_languages = 11\n",
    "# language_manager.load_ids_from_file('model_config/language_ids.json')\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80490701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speakers:  50\n",
      " > initialization of speaker-embedding layers.\n",
      " > initialization of language-embedding layers.\n"
     ]
    }
   ],
   "source": [
    "model = Vits(config, ap, tokenizer, speaker_manager, language_manager)\n",
    "# cp = torch.load('model_config/checkpoint_1433000.pth', \n",
    "#                 map_location=torch.device('cuda'))\n",
    "# model_weights = cp['model'].copy()\n",
    "# for key in list(model_weights.keys()):\n",
    "#   if \"speaker_encoder\" in key:\n",
    "#     del model_weights[key]\n",
    "# model.load_state_dict(model_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "594b4963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters  115227645\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Number of parameters \", count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f78402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 10:11:14,803.803 DEBUG local:  open file: /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/./TTS_Training/hindi_female-June-15-2023_10+11AM-f6af544/config.json\n",
      "2023-06-15 10:11:16,979.979 DEBUG local:  open file: /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/./TTS_Training/hindi_female-June-15-2023_10+11AM-f6af544/speakers.pth\n",
      "2023-06-15 10:11:16,982.982 DEBUG local:  open file: /root/Documents/Audio-Encoder-Pretraining-main/voice_coder/TTS_Training/./TTS_Training/hindi_female-June-15-2023_10+11AM-f6af544/language_ids.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > `speakers.pth` is saved to ./TTS_Training/hindi_female-June-15-2023_10+11AM-f6af544/speakers.pth.\n",
      " > `speakers_file` is updated in the config.json.\n",
      " > `language_ids.json` is saved to ./TTS_Training/hindi_female-June-15-2023_10+11AM-f6af544/language_ids.json.\n",
      " > `language_ids_file` is updated in the config.json.\n",
      "[*] Pre-computing phonemes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                  | 0/1486 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [!] Character 'f' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'Aː' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'y' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'a' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'r' not found in the vocabulary. Discarding it.\n",
      " [!] Character ' ' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'v' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'l' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'k' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'eː' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'i' not found in the vocabulary. Discarding it.\n",
      " [!] Character '' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'p' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'h' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'c' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'Eː' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'Iː' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'q' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'o' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'Uː' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'P' not found in the vocabulary. Discarding it.\n",
      " [!] Character 's' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'oː' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'g' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'x' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 4/1486 [00:00<02:26, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [!] Character 'M' not found in the vocabulary. Discarding it.\n",
      " [!] Character 't' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'm' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'z' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'n' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'B' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'u' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'J' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'b' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'T' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'C' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'j' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'V' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'D' not found in the vocabulary. Discarding it.\n",
      " [!] Character '|y' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'K' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'd' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                         | 6/1486 [00:00<02:40,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [!] Character '|x' not found in the vocabulary. Discarding it.\n",
      " [!] Character '|X' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'G' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'S' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'N' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'R' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                        | 11/1486 [00:00<01:51, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [!] Character 'n~' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'w' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                        | 21/1486 [00:02<02:36,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [!] Character '|g' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                        | 32/1486 [00:02<02:02, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [!] Character 'Y' not found in the vocabulary. Discarding it.\n",
      " [!] Character '|k' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                        | 40/1486 [00:03<02:25,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [!] Character '|K' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                       | 68/1486 [00:06<02:18, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [!] Character 'X' not found in the vocabulary. Discarding it.\n",
      " [!] Character '\\xa0h' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                      | 93/1486 [00:08<02:01, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [!] Character '`a' not found in the vocabulary. Discarding it.\n",
      " [!] Character 'e' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▊                                    | 142/1486 [00:12<01:50, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [!] Character '़f' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████▍                   | 758/1486 [01:06<01:02, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [!] Character '़|x' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████▋              | 952/1486 [01:23<00:45, 11.68it/s]"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")\n",
    "\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47554118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
